name: Vendor Crawl

on:
  workflow_dispatch:
    inputs:
      vendor_name:
        description: 'Vendor Name (e.g., Keeva)'
        required: true
        default: 'Vendor'
      start_url:
        description: 'Start URL'
        required: true
        default: 'https://keevaaexports.com/collections/all'
      page_limit:
        description: 'Page Limit'
        required: false
        default: '50'
        type: string

permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'

    - name: Install dependencies
      run: |
        pip install -r backend/requirements.txt
        python -m playwright install chromium

    - name: Run Crawler
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        # Optional:
        # AI_PROVIDER_BASE_URL: ${{ secrets.AI_PROVIDER_BASE_URL }}
        # AI_MODEL_NAME: ${{ secrets.AI_MODEL_NAME }}
      run: |
        python backend/main.py \
          --vendor_name "${{ inputs.vendor_name }}" \
          --start_url "${{ inputs.start_url }}" \
          --page_limit ${{ inputs.page_limit }}

    - name: Commit Results to Repo
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        git add frontend/data/
        # Only commit if there are changes
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update crawl results [skip ci]" && git push)
      
    - name: Upload Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: crawl-data
        path: frontend/data/
